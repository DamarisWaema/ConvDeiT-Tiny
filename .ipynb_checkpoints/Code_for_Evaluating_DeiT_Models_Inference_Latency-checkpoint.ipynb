{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05021b32-d922-4171-b7eb-b03dfe9994bd",
   "metadata": {},
   "source": [
    "# Evaluating DeiT-Ti for comparison with convDeit-Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ea3170-0dab-4dd9-b3ef-4259466f1c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T10:13:31.419788Z",
     "iopub.status.busy": "2025-12-03T10:13:31.418993Z",
     "iopub.status.idle": "2025-12-03T10:19:30.435705Z",
     "shell.execute_reply": "2025-12-03T10:19:30.434686Z",
     "shell.execute_reply.started": "2025-12-03T10:13:31.419730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Seed set to 42 and logged in 'seed_log.json'.\n",
      "MACs: 913,640,583\n",
      "FLOPs: 1,827,281,166\n",
      "Params: 5,524,995\n",
      "Total Trainable Parameters in deit_tiny model is: 5,524,995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 ‚Äî Loss: 0.8478, Val Accuracy: 60.68%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.386 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 ‚Äî Loss: 0.7146, Val Accuracy: 66.24%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.437 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 ‚Äî Loss: 0.6577, Val Accuracy: 61.97%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.307 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 ‚Äî Loss: 0.6274, Val Accuracy: 67.52%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.408 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 ‚Äî Loss: 0.5961, Val Accuracy: 70.51%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.452 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 ‚Äî Loss: 0.5518, Val Accuracy: 74.36%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.408 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 ‚Äî Loss: 0.5482, Val Accuracy: 79.49%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.669 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 ‚Äî Loss: 0.5401, Val Accuracy: 73.50%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.325 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 ‚Äî Loss: 0.6001, Val Accuracy: 76.92%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.412 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 ‚Äî Loss: 0.5107, Val Accuracy: 85.47%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.451 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11 ‚Äî Loss: 0.4430, Val Accuracy: 87.18%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.398 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12 ‚Äî Loss: 0.4545, Val Accuracy: 73.08%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.528 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13 ‚Äî Loss: 0.4506, Val Accuracy: 83.76%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.419 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14 ‚Äî Loss: 0.4445, Val Accuracy: 76.92%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.509 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15 ‚Äî Loss: 0.3822, Val Accuracy: 78.21%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.404 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  16 ‚Äî Loss: 0.4093, Val Accuracy: 85.04%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 5.300 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  17 ‚Äî Loss: 0.3265, Val Accuracy: 81.20%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 5.567 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  18 ‚Äî Loss: 0.3694, Val Accuracy: 84.62%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 5.396 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19 ‚Äî Loss: 0.2903, Val Accuracy: 85.90%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 5.424 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 ‚Äî Loss: 0.3159, Val Accuracy: 83.33%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 5.696 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21 ‚Äî Loss: 0.3325, Val Accuracy: 84.19%\n",
      "‚è≥ Patience Counter: 10/20\n",
      "‚è±Ô∏è Epoch Time: 5.514 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  22 ‚Äî Loss: 0.3175, Val Accuracy: 91.03%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.508 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  23 ‚Äî Loss: 0.2599, Val Accuracy: 87.61%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.436 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24 ‚Äî Loss: 0.2560, Val Accuracy: 84.19%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.343 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  25 ‚Äî Loss: 0.2494, Val Accuracy: 85.04%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.410 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  26 ‚Äî Loss: 0.2727, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.293 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  27 ‚Äî Loss: 0.2806, Val Accuracy: 85.47%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 5.455 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  28 ‚Äî Loss: 0.3375, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 5.505 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  29 ‚Äî Loss: 0.2366, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 5.390 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30 ‚Äî Loss: 0.2325, Val Accuracy: 83.76%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 5.460 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  31 ‚Äî Loss: 0.2810, Val Accuracy: 90.60%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 5.757 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  32 ‚Äî Loss: 0.2096, Val Accuracy: 93.16%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.497 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  33 ‚Äî Loss: 0.2271, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.278 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  34 ‚Äî Loss: 0.2106, Val Accuracy: 90.60%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.329 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  35 ‚Äî Loss: 0.1835, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.316 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  36 ‚Äî Loss: 0.1870, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.351 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  37 ‚Äî Loss: 0.2184, Val Accuracy: 88.89%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 5.337 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  38 ‚Äî Loss: 0.1859, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 5.365 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  39 ‚Äî Loss: 0.2078, Val Accuracy: 88.89%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 5.475 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 ‚Äî Loss: 0.1960, Val Accuracy: 93.16%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 5.398 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  41 ‚Äî Loss: 0.1670, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 5.400 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  42 ‚Äî Loss: 0.1651, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 10/20\n",
      "‚è±Ô∏è Epoch Time: 5.478 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  43 ‚Äî Loss: 0.1708, Val Accuracy: 93.59%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.573 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  44 ‚Äî Loss: 0.1556, Val Accuracy: 93.59%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.492 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  45 ‚Äî Loss: 0.2543, Val Accuracy: 90.60%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.387 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  46 ‚Äî Loss: 0.1800, Val Accuracy: 94.87%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.458 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  47 ‚Äî Loss: 0.1400, Val Accuracy: 93.59%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.458 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  48 ‚Äî Loss: 0.1497, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.473 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  49 ‚Äî Loss: 0.1308, Val Accuracy: 91.88%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.501 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 ‚Äî Loss: 0.1684, Val Accuracy: 94.44%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.493 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  51 ‚Äî Loss: 0.1352, Val Accuracy: 94.02%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 5.370 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  52 ‚Äî Loss: 0.1497, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 5.440 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  53 ‚Äî Loss: 0.1397, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 5.435 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  54 ‚Äî Loss: 0.1287, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 5.516 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  55 ‚Äî Loss: 0.1129, Val Accuracy: 87.18%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 5.426 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  56 ‚Äî Loss: 0.1457, Val Accuracy: 90.60%\n",
      "‚è≥ Patience Counter: 10/20\n",
      "‚è±Ô∏è Epoch Time: 5.462 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  57 ‚Äî Loss: 0.2036, Val Accuracy: 89.32%\n",
      "‚è≥ Patience Counter: 11/20\n",
      "‚è±Ô∏è Epoch Time: 5.377 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  58 ‚Äî Loss: 0.1319, Val Accuracy: 93.16%\n",
      "‚è≥ Patience Counter: 12/20\n",
      "‚è±Ô∏è Epoch Time: 5.385 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  59 ‚Äî Loss: 0.1157, Val Accuracy: 92.31%\n",
      "‚è≥ Patience Counter: 13/20\n",
      "‚è±Ô∏è Epoch Time: 5.243 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60 ‚Äî Loss: 0.1246, Val Accuracy: 92.31%\n",
      "‚è≥ Patience Counter: 14/20\n",
      "‚è±Ô∏è Epoch Time: 5.267 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  61 ‚Äî Loss: 0.1426, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 15/20\n",
      "‚è±Ô∏è Epoch Time: 5.519 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  62 ‚Äî Loss: 0.1430, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 16/20\n",
      "‚è±Ô∏è Epoch Time: 5.477 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  63 ‚Äî Loss: 0.1010, Val Accuracy: 94.44%\n",
      "‚è≥ Patience Counter: 17/20\n",
      "‚è±Ô∏è Epoch Time: 5.469 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  64 ‚Äî Loss: 0.1282, Val Accuracy: 94.44%\n",
      "‚è≥ Patience Counter: 18/20\n",
      "‚è±Ô∏è Epoch Time: 5.428 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  65 ‚Äî Loss: 0.1425, Val Accuracy: 94.87%\n",
      "‚è≥ Patience Counter: 19/20\n",
      "‚è±Ô∏è Epoch Time: 5.429 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  66 ‚Äî Loss: 0.1104, Val Accuracy: 93.16%\n",
      "‚è≥ Patience Counter: 20/20\n",
      "‚è±Ô∏è Epoch Time: 5.494 seconds\n",
      "üõë Early stopping triggered.\n",
      "\n",
      "üéØ Best Accuracy: 94.87% at Epoch 46\n",
      "\n",
      "===== TRAINING TIME SUMMARY =====\n",
      "‚è±Ô∏è First Epoch Time:       5.386 seconds\n",
      "‚è±Ô∏è Total Training Time:    358.766 seconds\n",
      "‚è±Ô∏è Avg Epoch Time:         5.436 seconds\n",
      "‚è±Ô∏è Time to Best Epoch (46): 250.102 seconds\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from torchvision.transforms import ColorJitter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from itertools import product\n",
    "import time\n",
    "#Flops and efficiency logging\n",
    "import time\n",
    "from ptflops import get_model_complexity_info\n",
    "# Seed setting\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === Reproducibility ===\n",
    "def set_seed(seed: int = 42, save_path: str = \"seed_log.json\"):\n",
    "    \"\"\"\n",
    "    Set the random seed for Python, NumPy, and PyTorch.\n",
    "    Saves the seed to a file so it can be reused later.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Save seed info\n",
    "    seed_data = {\n",
    "        \"seed\": seed\n",
    "    }\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(seed_data, f)\n",
    "\n",
    "    print(f\"[INFO] Seed set to {seed} and logged in '{save_path}'.\")\n",
    "set_seed (42)\n",
    "\n",
    "# === Set device ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"Return number of trainable params.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#Code for noise addition\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0.0, std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img).astype(np.float32) / 255.0\n",
    "        noise = np.random.normal(self.mean, self.std, img.shape)\n",
    "        noisy_img = np.clip(img + noise, 0, 1)\n",
    "        return Image.fromarray((noisy_img * 255).astype(np.uint8))\n",
    "\n",
    "class RandomNoiseBlurOrJitter:\n",
    "    def __init__(self, prob=0.2, noise_std=0.05, blur_radius=1, jitter_params=None):\n",
    "        self.prob = prob\n",
    "        self.noise_transform = AddGaussianNoise(std=noise_std)\n",
    "        self.blur_radius = blur_radius\n",
    "        self.jitter_transform = ColorJitter(**(jitter_params or {\n",
    "            'brightness': 0.2,\n",
    "            'contrast': 0.2,\n",
    "            'saturation': 0.2,\n",
    "            'hue': 0.1\n",
    "        }))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            choice = random.choice(['noise', 'blur', 'jitter'])\n",
    "            if choice == 'noise':\n",
    "                img = self.noise_transform(img)\n",
    "            elif choice == 'blur':\n",
    "                img = img.filter(ImageFilter.GaussianBlur(radius=self.blur_radius))\n",
    "            elif choice == 'jitter':\n",
    "                img = self.jitter_transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "#Data transformation and loading\n",
    "\n",
    "# === Data transforms ===\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(270),\n",
    "    RandomNoiseBlurOrJitter(prob=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    RandomNoiseBlurOrJitter(prob=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "\n",
    "# === Load datasets ===\n",
    "train_dataset = datasets.ImageFolder('CDS_Dataset/train', transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder('CDS_Dataset/val', transform=transform_val)\n",
    "class_names = train_dataset.classes\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Instantiate and move to device\n",
    "model = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=len(class_names)).to(device)\n",
    "model.to(device)\n",
    "macs, params = get_model_complexity_info(\n",
    "    model,\n",
    "    (3, 224, 224),  # input size\n",
    "    as_strings=False,   # üëà key: return float values\n",
    "    print_per_layer_stat=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Convert MACs ‚Üí FLOPs (1 MAC = 2 FLOPs)\n",
    "flops = macs * 2  \n",
    "\n",
    "print(f\"MACs: {macs:,}\")   # commas for readability\n",
    "print(f\"FLOPs: {flops:,}\") # expanded number\n",
    "print(f\"Params: {params:,}\")\n",
    "print(f\"Total Trainable Parameters in deit_tiny model is: {count_params(model):,}\")\n",
    "\n",
    " # REMOVE TO STOP USING GRID SEARCH\n",
    "# === Loss and optimizer ===\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "scheduler = None\n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Training with Early Stopping ===\n",
    "best_acc = 0.0\n",
    "epochs = 200\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "best_epoch = 0\n",
    "\n",
    "first_epoch_time = None\n",
    "total_training_time = 0.0\n",
    "# We'll store each epoch's elapsed time so we can accurately sum up to best_epoch later\n",
    "epoch_times = []\n",
    "\n",
    "epochs_completed = 0  # counts how many full epochs we actually ran\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- start epoch timer ----\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_start = time.perf_counter()\n",
    "    # ---------------------------\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1:>3} ‚Äî Loss: {avg_loss:.4f}, Val Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    # --- Decide improvement ---\n",
    "    improved = False\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        improved = True\n",
    "\n",
    "        # save model\n",
    "        torch.save(model.state_dict(), 'CDS_best_scratch_deit_tiny.pth')\n",
    "        print(\"‚úÖ New best model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚è≥ Patience Counter: {patience_counter}/{patience}\")\n",
    "\n",
    "    # ---- stop epoch timer ----\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_end = time.perf_counter()\n",
    "    epoch_time = epoch_end - epoch_start\n",
    "\n",
    "    # record times\n",
    "    epoch_times.append(epoch_time)\n",
    "    total_training_time += epoch_time\n",
    "    epochs_completed += 1\n",
    "\n",
    "    if first_epoch_time is None:\n",
    "        first_epoch_time = epoch_time\n",
    "\n",
    "    print(f\"‚è±Ô∏è Epoch Time: {epoch_time:.3f} seconds\")\n",
    "\n",
    "    # Early stopping check AFTER timing so final epoch time is included\n",
    "    if patience_counter >= patience:\n",
    "        print(\"üõë Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# End training loop\n",
    "avg_epoch_time = total_training_time / epochs_completed if epochs_completed > 0 else None\n",
    "\n",
    "# --- Compute time_to_best_epoch correctly ---\n",
    "if best_epoch > 0 and len(epoch_times) >= best_epoch:\n",
    "    # best_epoch is 1-based; sum epoch_times up to and including best_epoch\n",
    "    time_to_best_epoch = sum(epoch_times[:best_epoch])\n",
    "else:\n",
    "    time_to_best_epoch = None\n",
    "\n",
    "print(f\"\\nüéØ Best Accuracy: {best_acc*100:.2f}% at Epoch {best_epoch}\")\n",
    "\n",
    "# === Print timing summary ===\n",
    "print(\"\\n===== TRAINING TIME SUMMARY =====\")\n",
    "print(f\"‚è±Ô∏è First Epoch Time:       {first_epoch_time:.3f} seconds\" if first_epoch_time is not None else \"First epoch time: N/A\")\n",
    "print(f\"‚è±Ô∏è Total Training Time:    {total_training_time:.3f} seconds\")\n",
    "print(f\"‚è±Ô∏è Avg Epoch Time:         {avg_epoch_time:.3f} seconds\" if avg_epoch_time is not None else \"Avg epoch time: N/A\")\n",
    "\n",
    "if time_to_best_epoch is not None:\n",
    "    print(f\"‚è±Ô∏è Time to Best Epoch ({best_epoch}): {time_to_best_epoch:.3f} seconds\")\n",
    "else:\n",
    "    print(\"‚è±Ô∏è Time to Best Epoch:      No improvement recorded (best never updated)\")\n",
    "\n",
    "print(\"=================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31b9a28-3e9b-44c6-9223-b0cda17e3a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T12:43:58.706919Z",
     "iopub.status.busy": "2025-12-03T12:43:58.706057Z",
     "iopub.status.idle": "2025-12-03T12:44:06.321558Z",
     "shell.execute_reply": "2025-12-03T12:44:06.320592Z",
     "shell.execute_reply.started": "2025-12-03T12:43:58.706888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Seed set to 42 -> seed_log.json\n",
      "[INFO] Device: cuda; batch size: 32; dataset size: 234\n",
      "[INFO] Completed 30 warmup batches.\n",
      "\n",
      "===== INFERENCE TIMING SUMMARY =====\n",
      "Mode: INCLUDING host->device transfer\n",
      "  count_batches: 40\n",
      "  median_ms_per_image: 0.9350906766485423\n",
      "  mean_ms_per_image: 0.8636883969302289\n",
      "  std_ms_per_image: 0.20787211266480954\n",
      "  p95_ms_per_image: 0.9620443946914747\n",
      "  throughput_img_per_sec (median): 1069.4150043117734\n",
      "\n",
      "Mode: MODEL-ONLY (inputs already on device)\n",
      "  count_batches: 40\n",
      "  median_ms_per_image: 0.8895819773897529\n",
      "  mean_ms_per_image: 0.818375418020878\n",
      "  std_ms_per_image: 0.19368729607215987\n",
      "  p95_ms_per_image: 0.9015873074531555\n",
      "  throughput_img_per_sec (median): 1124.1234932998982\n",
      "====================================\n",
      "\n",
      "‚úÖ Test Accuracy: 95.7265% (n=1170)\n",
      "\n",
      "Confusion matrix computed.\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         gls     0.9861    0.9103    0.9467       390\n",
      "         nlb     0.9012    0.9865    0.9419       370\n",
      "         nls     0.9877    0.9756    0.9816       410\n",
      "\n",
      "    accuracy                         0.9573      1170\n",
      "   macro avg     0.9583    0.9575    0.9567      1170\n",
      "weighted avg     0.9598    0.9573    0.9574      1170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# -------------------------\n",
    "# Config (edit as needed)\n",
    "# -------------------------\n",
    "DATA_DIR = \"CDS_Dataset/test\"\n",
    "MODEL_PATH = \"CDS_best_scratch_deit_tiny.pth\"\n",
    "MODEL_NAME = \"deit_tiny_patch16_224\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "WARMUP_BATCHES = 30        \n",
    "MEASUREMENT_RUNS = 5      \n",
    "PIN_MEMORY = True\n",
    "NUM_WORKERS = 4            \n",
    "SEED = 42\n",
    "# -------------------------\n",
    "\n",
    "# --- reproducibility (note: full determinism not guaranteed for timings) ---\n",
    "def set_seed(seed=SEED, save_path=\"seed_log.json\"):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump({\"seed\": seed}, f)\n",
    "    print(f\"[INFO] Seed set to {seed} -> {save_path}\")\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# --- dataset & loader ---\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(DATA_DIR, transform=transform_test)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "# --- model load ---\n",
    "model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=len(test_dataset.classes))\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# --- helper to synchronize safely ---\n",
    "def sync_device():\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "# --- warmup ---\n",
    "def do_warmup(model, loader, warmup_batches=WARMUP_BATCHES):\n",
    "    model.eval()\n",
    "    it = iter(loader)\n",
    "    with torch.no_grad():\n",
    "        for i in range(warmup_batches):\n",
    "            try:\n",
    "                images, _ = next(it)\n",
    "            except StopIteration:\n",
    "                it = iter(loader)\n",
    "                images, _ = next(it)\n",
    "            # move to device and run\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            _ = model(images)\n",
    "            sync_device()\n",
    "    print(f\"[INFO] Completed {warmup_batches} warmup batches.\")\n",
    "\n",
    "# --- measurement: returns lists of per-batch times (seconds) for two modes ---\n",
    "def measure_runs(model, loader, runs=MEASUREMENT_RUNS):\n",
    "    model.eval()\n",
    "    all_batch_times_including_transfer = []\n",
    "    all_batch_times_model_only = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for r in range(runs):\n",
    "            # iterate through dataset once\n",
    "            for images, labels in loader:\n",
    "                batch_size = images.size(0)\n",
    "\n",
    "                # 1) Measure end-to-end (host->device transfer + forward)\n",
    "                start = time.perf_counter()\n",
    "                images_dev = images.to(DEVICE, non_blocking=True)\n",
    "                outputs = model(images_dev)\n",
    "                sync_device()\n",
    "                end = time.perf_counter()\n",
    "                all_batch_times_including_transfer.append(end - start)\n",
    "\n",
    "                # 2) Measure model-only: move inputs first (exclude transfer)\n",
    "                images_dev2 = images.to(DEVICE, non_blocking=True)  # move outside timing\n",
    "                sync_device()\n",
    "                start2 = time.perf_counter()\n",
    "                outputs2 = model(images_dev2)\n",
    "                sync_device()\n",
    "                end2 = time.perf_counter()\n",
    "                all_batch_times_model_only.append(end2 - start2)\n",
    "\n",
    "                # collect predictions from outputs2 (or outputs)\n",
    "                if isinstance(outputs2, tuple):\n",
    "                    outputs2 = outputs2[0]\n",
    "                _, preds = torch.max(outputs2, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "\n",
    "    return {\n",
    "        \"batch_times_including_transfer\": np.array(all_batch_times_including_transfer),\n",
    "        \"batch_times_model_only\": np.array(all_batch_times_model_only),\n",
    "        \"all_preds\": np.array(all_preds),\n",
    "        \"all_labels\": np.array(all_labels)\n",
    "    }\n",
    "\n",
    "# --- run warmup and measure ---\n",
    "print(f\"[INFO] Device: {DEVICE}; batch size: {BATCH_SIZE}; dataset size: {len(test_dataset)}\")\n",
    "do_warmup(model, test_loader, warmup_batches=WARMUP_BATCHES)\n",
    "\n",
    "# Clear CUDA cache to get more consistent results \n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "measurements = measure_runs(model, test_loader, runs=MEASUREMENT_RUNS)\n",
    "\n",
    "# --- compute stats ---\n",
    "def summarize_batch_times(batch_times, batch_size=BATCH_SIZE):\n",
    "    # per-image latencies for each batch\n",
    "    per_batch_sizes = np.full_like(batch_times, batch_size, dtype=float)\n",
    "    per_image = batch_times / per_batch_sizes  # seconds per image\n",
    "    return {\n",
    "        \"count_batches\": int(len(batch_times)),\n",
    "        \"median_ms_per_image\": float(np.median(per_image) * 1000.0),\n",
    "        \"mean_ms_per_image\": float(np.mean(per_image) * 1000.0),\n",
    "        \"std_ms_per_image\": float(np.std(per_image) * 1000.0),\n",
    "        \"p95_ms_per_image\": float(np.percentile(per_image, 95) * 1000.0),\n",
    "        \"throughput_img_per_sec (median)\": 1000.0 / float(np.median(per_image) * 1000.0) if np.median(per_image) > 0 else float(\"inf\"),\n",
    "        \"raw_per_image_ms\": per_image * 1000.0  # keep for later analysis/plotting if needed\n",
    "    }\n",
    "\n",
    "batch_size_actual = BATCH_SIZE\n",
    "inc_summary = summarize_batch_times(measurements[\"batch_times_including_transfer\"], batch_size=batch_size_actual)\n",
    "model_only_summary = summarize_batch_times(measurements[\"batch_times_model_only\"], batch_size=batch_size_actual)\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"\\n===== INFERENCE TIMING SUMMARY =====\")\n",
    "print(\"Mode: INCLUDING host->device transfer\")\n",
    "for k, v in inc_summary.items():\n",
    "    if k != \"raw_per_image_ms\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(\"\\nMode: MODEL-ONLY (inputs already on device)\")\n",
    "for k, v in model_only_summary.items():\n",
    "    if k != \"raw_per_image_ms\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(\"====================================\\n\")\n",
    "\n",
    "# --- Accuracy / Reports ---\n",
    "all_preds = measurements[\"all_preds\"][: len(measurements[\"all_labels\"])]  # safety trim\n",
    "all_labels = measurements[\"all_labels\"]\n",
    "correct = (all_preds == all_labels).sum()\n",
    "accuracy = 100.0 * correct / len(all_labels)\n",
    "print(f\"‚úÖ Test Accuracy: {accuracy:.4f}% (n={len(all_labels)})\")\n",
    "\n",
    "# Confusion matrix and classification report \n",
    "try:\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\nConfusion matrix computed.\")\n",
    "    report = classification_report(all_labels, all_preds, target_names=test_dataset.classes, digits=4)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "except Exception as e:\n",
    "    print(\"Failed to compute classification report:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4d14b-26ed-4cdd-8c59-13e270e87916",
   "metadata": {},
   "source": [
    "# Evaluating DeiT-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fba364-9d87-4e2e-994e-f32f50c27105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T09:42:40.940910Z",
     "iopub.status.busy": "2025-12-03T09:42:40.940615Z",
     "iopub.status.idle": "2025-12-03T10:00:28.108470Z",
     "shell.execute_reply": "2025-12-03T10:00:28.107539Z",
     "shell.execute_reply.started": "2025-12-03T09:42:40.940889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/mobileViTV2CDS/mobileViTV2CDS-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Seed set to 42 and logged in 'seed_log.json'.\n",
      "MACs: 3,221,625,099\n",
      "FLOPs: 6,443,250,198\n",
      "Params: 21,666,819\n",
      "Total Trainable Parameters in deit_small model is: 21,666,819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 ‚Äî Loss: 0.8970, Val Accuracy: 58.12%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 12.647 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 ‚Äî Loss: 0.7449, Val Accuracy: 65.38%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 10.979 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 ‚Äî Loss: 0.6824, Val Accuracy: 68.80%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.021 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 ‚Äî Loss: 0.6529, Val Accuracy: 69.23%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 10.951 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 ‚Äî Loss: 0.5777, Val Accuracy: 63.68%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.904 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 ‚Äî Loss: 0.5581, Val Accuracy: 77.35%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.093 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 ‚Äî Loss: 0.5325, Val Accuracy: 67.09%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.934 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 ‚Äî Loss: 0.5177, Val Accuracy: 75.64%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.986 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 ‚Äî Loss: 0.4489, Val Accuracy: 73.08%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 11.014 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 ‚Äî Loss: 0.4526, Val Accuracy: 84.19%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.144 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11 ‚Äî Loss: 0.4018, Val Accuracy: 79.49%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 11.026 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12 ‚Äî Loss: 0.3802, Val Accuracy: 83.76%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.991 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13 ‚Äî Loss: 0.3730, Val Accuracy: 84.62%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.128 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14 ‚Äî Loss: 0.3700, Val Accuracy: 84.62%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.936 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15 ‚Äî Loss: 0.3365, Val Accuracy: 83.76%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.905 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  16 ‚Äî Loss: 0.3317, Val Accuracy: 88.03%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.200 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  17 ‚Äî Loss: 0.3128, Val Accuracy: 84.19%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.926 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  18 ‚Äî Loss: 0.2838, Val Accuracy: 86.32%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.926 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19 ‚Äî Loss: 0.2357, Val Accuracy: 86.32%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 10.932 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 ‚Äî Loss: 0.4524, Val Accuracy: 86.75%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 10.983 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21 ‚Äî Loss: 0.3001, Val Accuracy: 89.32%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.270 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  22 ‚Äî Loss: 0.3543, Val Accuracy: 85.04%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.982 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  23 ‚Äî Loss: 0.3124, Val Accuracy: 85.47%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.980 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24 ‚Äî Loss: 0.2315, Val Accuracy: 88.03%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 10.976 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  25 ‚Äî Loss: 0.2344, Val Accuracy: 87.18%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 10.942 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  26 ‚Äî Loss: 0.2724, Val Accuracy: 88.03%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 10.917 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  27 ‚Äî Loss: 0.2618, Val Accuracy: 81.20%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 11.067 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  28 ‚Äî Loss: 0.2511, Val Accuracy: 90.17%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.269 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  29 ‚Äî Loss: 0.2466, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.940 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30 ‚Äî Loss: 0.2077, Val Accuracy: 91.03%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.110 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  31 ‚Äî Loss: 0.2260, Val Accuracy: 89.32%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 11.035 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  32 ‚Äî Loss: 0.1886, Val Accuracy: 91.88%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.166 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  33 ‚Äî Loss: 0.1866, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 11.214 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  34 ‚Äî Loss: 0.1604, Val Accuracy: 90.60%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.881 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  35 ‚Äî Loss: 0.1967, Val Accuracy: 87.18%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 10.912 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  36 ‚Äî Loss: 0.1669, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 11.079 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  37 ‚Äî Loss: 0.2119, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 11.051 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  38 ‚Äî Loss: 0.2005, Val Accuracy: 89.74%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 10.998 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  39 ‚Äî Loss: 0.1514, Val Accuracy: 84.19%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 10.959 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 ‚Äî Loss: 0.1941, Val Accuracy: 91.88%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 10.974 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  41 ‚Äî Loss: 0.1821, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 10.996 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  42 ‚Äî Loss: 0.1468, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 10/20\n",
      "‚è±Ô∏è Epoch Time: 10.970 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  43 ‚Äî Loss: 0.1827, Val Accuracy: 85.47%\n",
      "‚è≥ Patience Counter: 11/20\n",
      "‚è±Ô∏è Epoch Time: 11.019 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  44 ‚Äî Loss: 0.1693, Val Accuracy: 93.16%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.148 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  45 ‚Äî Loss: 0.1709, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 11.002 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  46 ‚Äî Loss: 0.1390, Val Accuracy: 92.31%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.920 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  47 ‚Äî Loss: 0.1468, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 10.970 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  48 ‚Äî Loss: 0.2063, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 11.000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  49 ‚Äî Loss: 0.1497, Val Accuracy: 94.44%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.064 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 ‚Äî Loss: 0.1313, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.912 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  51 ‚Äî Loss: 0.1374, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.909 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  52 ‚Äî Loss: 0.1284, Val Accuracy: 88.89%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 10.943 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  53 ‚Äî Loss: 0.1472, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 11.020 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  54 ‚Äî Loss: 0.1374, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 10.952 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  55 ‚Äî Loss: 0.1392, Val Accuracy: 94.44%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 10.983 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  56 ‚Äî Loss: 0.1216, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 10.957 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  57 ‚Äî Loss: 0.1519, Val Accuracy: 94.44%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 10.943 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  58 ‚Äî Loss: 0.1206, Val Accuracy: 94.02%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 11.065 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  59 ‚Äî Loss: 0.1072, Val Accuracy: 94.87%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.267 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  60 ‚Äî Loss: 0.1353, Val Accuracy: 92.31%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 10.993 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  61 ‚Äî Loss: 0.1086, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 11.109 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  62 ‚Äî Loss: 0.1728, Val Accuracy: 89.74%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 10.989 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  63 ‚Äî Loss: 0.1338, Val Accuracy: 91.88%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 11.185 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  64 ‚Äî Loss: 0.1340, Val Accuracy: 92.31%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 11.112 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  65 ‚Äî Loss: 0.1889, Val Accuracy: 77.35%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 11.071 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  66 ‚Äî Loss: 0.2093, Val Accuracy: 93.16%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 10.983 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  67 ‚Äî Loss: 0.1254, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 10.937 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  68 ‚Äî Loss: 0.0788, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 10.943 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  69 ‚Äî Loss: 0.1510, Val Accuracy: 93.16%\n",
      "‚è≥ Patience Counter: 10/20\n",
      "‚è±Ô∏è Epoch Time: 11.110 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  70 ‚Äî Loss: 0.1110, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 11/20\n",
      "‚è±Ô∏è Epoch Time: 11.003 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  71 ‚Äî Loss: 0.1229, Val Accuracy: 92.31%\n",
      "‚è≥ Patience Counter: 12/20\n",
      "‚è±Ô∏è Epoch Time: 11.081 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  72 ‚Äî Loss: 0.1161, Val Accuracy: 93.59%\n",
      "‚è≥ Patience Counter: 13/20\n",
      "‚è±Ô∏è Epoch Time: 10.977 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  73 ‚Äî Loss: 0.1000, Val Accuracy: 94.02%\n",
      "‚è≥ Patience Counter: 14/20\n",
      "‚è±Ô∏è Epoch Time: 11.079 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  74 ‚Äî Loss: 0.1119, Val Accuracy: 95.30%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 11.173 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  75 ‚Äî Loss: 0.1402, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 11.009 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  76 ‚Äî Loss: 0.1129, Val Accuracy: 93.59%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 10.910 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  77 ‚Äî Loss: 0.1090, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 10.991 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  78 ‚Äî Loss: 0.1181, Val Accuracy: 93.16%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 11.000 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  79 ‚Äî Loss: 0.1242, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 10.972 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  80 ‚Äî Loss: 0.1109, Val Accuracy: 92.31%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 11.010 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  81 ‚Äî Loss: 0.0902, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 11.014 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  82 ‚Äî Loss: 0.0970, Val Accuracy: 95.30%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 11.045 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  83 ‚Äî Loss: 0.1285, Val Accuracy: 87.18%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 11.020 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  84 ‚Äî Loss: 0.1295, Val Accuracy: 95.30%\n",
      "‚è≥ Patience Counter: 10/20\n",
      "‚è±Ô∏è Epoch Time: 11.081 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  85 ‚Äî Loss: 0.1147, Val Accuracy: 94.02%\n",
      "‚è≥ Patience Counter: 11/20\n",
      "‚è±Ô∏è Epoch Time: 11.070 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  86 ‚Äî Loss: 0.1219, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 12/20\n",
      "‚è±Ô∏è Epoch Time: 10.986 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  87 ‚Äî Loss: 0.1459, Val Accuracy: 94.44%\n",
      "‚è≥ Patience Counter: 13/20\n",
      "‚è±Ô∏è Epoch Time: 11.055 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  88 ‚Äî Loss: 0.0839, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 14/20\n",
      "‚è±Ô∏è Epoch Time: 11.028 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  89 ‚Äî Loss: 0.0852, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 15/20\n",
      "‚è±Ô∏è Epoch Time: 10.962 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  90 ‚Äî Loss: 0.1096, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 16/20\n",
      "‚è±Ô∏è Epoch Time: 10.975 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  91 ‚Äî Loss: 0.1428, Val Accuracy: 94.44%\n",
      "‚è≥ Patience Counter: 17/20\n",
      "‚è±Ô∏è Epoch Time: 11.019 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  92 ‚Äî Loss: 0.1127, Val Accuracy: 94.02%\n",
      "‚è≥ Patience Counter: 18/20\n",
      "‚è±Ô∏è Epoch Time: 11.081 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  93 ‚Äî Loss: 0.0656, Val Accuracy: 92.74%\n",
      "‚è≥ Patience Counter: 19/20\n",
      "‚è±Ô∏è Epoch Time: 11.114 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  94 ‚Äî Loss: 0.0807, Val Accuracy: 93.16%\n",
      "‚è≥ Patience Counter: 20/20\n",
      "‚è±Ô∏è Epoch Time: 10.954 seconds\n",
      "üõë Early stopping triggered.\n",
      "\n",
      "üéØ Best Accuracy: 95.30% at Epoch 74\n",
      "\n",
      "===== TRAINING TIME SUMMARY =====\n",
      "‚è±Ô∏è First Epoch Time:       12.647 seconds\n",
      "‚è±Ô∏è Total Training Time:    1037.431 seconds\n",
      "‚è±Ô∏è Avg Epoch Time:         11.037 seconds\n",
      "‚è±Ô∏è Time to Best Epoch (74): 817.135 seconds\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from torchvision.transforms import ColorJitter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from itertools import product\n",
    "import time\n",
    "#Flops and efficiency logging\n",
    "import time\n",
    "from ptflops import get_model_complexity_info\n",
    "# Seed setting\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === Reproducibility ===\n",
    "def set_seed(seed: int = 42, save_path: str = \"seed_log.json\"):\n",
    "    \"\"\"\n",
    "    Set the random seed for Python, NumPy, and PyTorch.\n",
    "    Saves the seed to a file so it can be reused later.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Save seed info\n",
    "    seed_data = {\n",
    "        \"seed\": seed\n",
    "    }\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(seed_data, f)\n",
    "\n",
    "    print(f\"[INFO] Seed set to {seed} and logged in '{save_path}'.\")\n",
    "set_seed (42)\n",
    "\n",
    "# === Set device ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"Return number of trainable params.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#Code for noise addition\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0.0, std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img).astype(np.float32) / 255.0\n",
    "        noise = np.random.normal(self.mean, self.std, img.shape)\n",
    "        noisy_img = np.clip(img + noise, 0, 1)\n",
    "        return Image.fromarray((noisy_img * 255).astype(np.uint8))\n",
    "\n",
    "class RandomNoiseBlurOrJitter:\n",
    "    def __init__(self, prob=0.2, noise_std=0.05, blur_radius=1, jitter_params=None):\n",
    "        self.prob = prob\n",
    "        self.noise_transform = AddGaussianNoise(std=noise_std)\n",
    "        self.blur_radius = blur_radius\n",
    "        self.jitter_transform = ColorJitter(**(jitter_params or {\n",
    "            'brightness': 0.2,\n",
    "            'contrast': 0.2,\n",
    "            'saturation': 0.2,\n",
    "            'hue': 0.1\n",
    "        }))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            choice = random.choice(['noise', 'blur', 'jitter'])\n",
    "            if choice == 'noise':\n",
    "                img = self.noise_transform(img)\n",
    "            elif choice == 'blur':\n",
    "                img = img.filter(ImageFilter.GaussianBlur(radius=self.blur_radius))\n",
    "            elif choice == 'jitter':\n",
    "                img = self.jitter_transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "#Data transformation and loading\n",
    "\n",
    "# === Data transforms ===\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(270),\n",
    "    RandomNoiseBlurOrJitter(prob=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    RandomNoiseBlurOrJitter(prob=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "\n",
    "# === Load datasets ===\n",
    "train_dataset = datasets.ImageFolder('CDS_Dataset/train', transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder('CDS_Dataset/val', transform=transform_val)\n",
    "class_names = train_dataset.classes\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Instantiate and move to device\n",
    "model = timm.create_model('deit_small_patch16_224', pretrained=False, num_classes=len(class_names)).to(device)\n",
    "model.to(device)\n",
    "macs, params = get_model_complexity_info(\n",
    "    model,\n",
    "    (3, 224, 224),  # input size\n",
    "    as_strings=False,   # üëà key: return float values\n",
    "    print_per_layer_stat=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Convert MACs ‚Üí FLOPs (1 MAC = 2 FLOPs)\n",
    "flops = macs * 2  \n",
    "\n",
    "print(f\"MACs: {macs:,}\")   # commas for readability\n",
    "print(f\"FLOPs: {flops:,}\") # expanded number\n",
    "print(f\"Params: {params:,}\")\n",
    "print(f\"Total Trainable Parameters in deit_small model is: {count_params(model):,}\")\n",
    "\n",
    " # REMOVE TO STOP USING GRID SEARCH\n",
    "# === Loss and optimizer ===\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "scheduler = None\n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Training with Early Stopping ===\n",
    "best_acc = 0.0\n",
    "epochs = 200\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "best_epoch = 0\n",
    "\n",
    "first_epoch_time = None\n",
    "total_training_time = 0.0\n",
    "# We'll store each epoch's elapsed time so we can accurately sum up to best_epoch later\n",
    "epoch_times = []\n",
    "\n",
    "epochs_completed = 0  # counts how many full epochs we actually ran\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- start epoch timer ----\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_start = time.perf_counter()\n",
    "    # ---------------------------\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1:>3} ‚Äî Loss: {avg_loss:.4f}, Val Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    # --- Decide improvement ---\n",
    "    improved = False\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        improved = True\n",
    "\n",
    "        # save model\n",
    "        torch.save(model.state_dict(), 'CDS_best_scratch_deit_small.pth')\n",
    "        print(\"‚úÖ New best model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚è≥ Patience Counter: {patience_counter}/{patience}\")\n",
    "\n",
    "    # ---- stop epoch timer ----\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_end = time.perf_counter()\n",
    "    epoch_time = epoch_end - epoch_start\n",
    "\n",
    "    # record times\n",
    "    epoch_times.append(epoch_time)\n",
    "    total_training_time += epoch_time\n",
    "    epochs_completed += 1\n",
    "\n",
    "    if first_epoch_time is None:\n",
    "        first_epoch_time = epoch_time\n",
    "\n",
    "    print(f\"‚è±Ô∏è Epoch Time: {epoch_time:.3f} seconds\")\n",
    "\n",
    "    # Early stopping check AFTER timing so final epoch time is included\n",
    "    if patience_counter >= patience:\n",
    "        print(\"üõë Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# End training loop\n",
    "avg_epoch_time = total_training_time / epochs_completed if epochs_completed > 0 else None\n",
    "\n",
    "# --- Compute time_to_best_epoch correctly ---\n",
    "if best_epoch > 0 and len(epoch_times) >= best_epoch:\n",
    "    # best_epoch is 1-based; sum epoch_times up to and including best_epoch\n",
    "    time_to_best_epoch = sum(epoch_times[:best_epoch])\n",
    "else:\n",
    "    time_to_best_epoch = None\n",
    "\n",
    "print(f\"\\nüéØ Best Accuracy: {best_acc*100:.2f}% at Epoch {best_epoch}\")\n",
    "\n",
    "# === Print timing summary ===\n",
    "print(\"\\n===== TRAINING TIME SUMMARY =====\")\n",
    "print(f\"‚è±Ô∏è First Epoch Time:       {first_epoch_time:.3f} seconds\" if first_epoch_time is not None else \"First epoch time: N/A\")\n",
    "print(f\"‚è±Ô∏è Total Training Time:    {total_training_time:.3f} seconds\")\n",
    "print(f\"‚è±Ô∏è Avg Epoch Time:         {avg_epoch_time:.3f} seconds\" if avg_epoch_time is not None else \"Avg epoch time: N/A\")\n",
    "\n",
    "if time_to_best_epoch is not None:\n",
    "    print(f\"‚è±Ô∏è Time to Best Epoch ({best_epoch}): {time_to_best_epoch:.3f} seconds\")\n",
    "else:\n",
    "    print(\"‚è±Ô∏è Time to Best Epoch:      No improvement recorded (best never updated)\")\n",
    "\n",
    "print(\"=================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3193fc5d-cbea-4b8b-8a9f-955b4b024cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T12:04:25.425775Z",
     "iopub.status.busy": "2025-12-03T12:04:25.424994Z",
     "iopub.status.idle": "2025-12-03T12:04:38.381109Z",
     "shell.execute_reply": "2025-12-03T12:04:38.379799Z",
     "shell.execute_reply.started": "2025-12-03T12:04:25.425749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Seed set to 42 -> seed_log.json\n",
      "[INFO] Device: cuda; batch size: 32; dataset size: 234\n",
      "[INFO] Completed 30 warmup batches.\n",
      "\n",
      "===== INFERENCE TIMING SUMMARY =====\n",
      "Mode: INCLUDING host->device transfer\n",
      "  count_batches: 40\n",
      "  median_ms_per_image: 2.569360804045573\n",
      "  mean_ms_per_image: 2.352849318413064\n",
      "  std_ms_per_image: 0.5818728886841583\n",
      "  p95_ms_per_image: 2.586820616852492\n",
      "  throughput_img_per_sec (median): 389.2018584643525\n",
      "\n",
      "Mode: MODEL-ONLY (inputs already on device)\n",
      "  count_batches: 40\n",
      "  median_ms_per_image: 2.5304446171503514\n",
      "  mean_ms_per_image: 2.3137328229495324\n",
      "  std_ms_per_image: 0.570231185296596\n",
      "  p95_ms_per_image: 2.541453650337644\n",
      "  throughput_img_per_sec (median): 395.1874675392601\n",
      "====================================\n",
      "\n",
      "‚úÖ Test Accuracy: 95.2991% (n=1170)\n",
      "\n",
      "Confusion matrix computed.\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         gls     0.9726    0.9103    0.9404       390\n",
      "         nlb     0.9103    0.9595    0.9342       370\n",
      "         nls     0.9759    0.9878    0.9818       410\n",
      "\n",
      "    accuracy                         0.9530      1170\n",
      "   macro avg     0.9529    0.9525    0.9521      1170\n",
      "weighted avg     0.9540    0.9530    0.9530      1170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# -------------------------\n",
    "# Config \n",
    "# -------------------------\n",
    "DATA_DIR = \"CDS_Dataset/test\"\n",
    "MODEL_PATH = \"CDS_best_scratch_deit_small.pth\"\n",
    "MODEL_NAME = \"deit_small_patch16_224\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "WARMUP_BATCHES = 30        \n",
    "MEASUREMENT_RUNS = 5       \n",
    "PIN_MEMORY = True\n",
    "NUM_WORKERS = 4            \n",
    "SEED = 42\n",
    "# -------------------------\n",
    "\n",
    "# --- reproducibility (note: full determinism not guaranteed for timings) ---\n",
    "def set_seed(seed=SEED, save_path=\"seed_log.json\"):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump({\"seed\": seed}, f)\n",
    "    print(f\"[INFO] Seed set to {seed} -> {save_path}\")\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# --- dataset & loader ---\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(DATA_DIR, transform=transform_test)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "# --- model load ---\n",
    "model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=len(test_dataset.classes))\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# --- helper to synchronize safely ---\n",
    "def sync_device():\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "# --- warmup ---\n",
    "def do_warmup(model, loader, warmup_batches=WARMUP_BATCHES):\n",
    "    model.eval()\n",
    "    it = iter(loader)\n",
    "    with torch.no_grad():\n",
    "        for i in range(warmup_batches):\n",
    "            try:\n",
    "                images, _ = next(it)\n",
    "            except StopIteration:\n",
    "                it = iter(loader)\n",
    "                images, _ = next(it)\n",
    "            # move to device and run\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            _ = model(images)\n",
    "            sync_device()\n",
    "    print(f\"[INFO] Completed {warmup_batches} warmup batches.\")\n",
    "\n",
    "# --- measurement: returns lists of per-batch times (seconds) for two modes ---\n",
    "def measure_runs(model, loader, runs=MEASUREMENT_RUNS):\n",
    "    model.eval()\n",
    "    all_batch_times_including_transfer = []\n",
    "    all_batch_times_model_only = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for r in range(runs):\n",
    "            # iterate through dataset once\n",
    "            for images, labels in loader:\n",
    "                batch_size = images.size(0)\n",
    "\n",
    "                # 1) Measure end-to-end (host->device transfer + forward)\n",
    "                start = time.perf_counter()\n",
    "                images_dev = images.to(DEVICE, non_blocking=True)\n",
    "                outputs = model(images_dev)\n",
    "                sync_device()\n",
    "                end = time.perf_counter()\n",
    "                all_batch_times_including_transfer.append(end - start)\n",
    "\n",
    "                # 2) Measure model-only: move inputs first (exclude transfer)\n",
    "                images_dev2 = images.to(DEVICE, non_blocking=True)  # move outside timing\n",
    "                sync_device()\n",
    "                start2 = time.perf_counter()\n",
    "                outputs2 = model(images_dev2)\n",
    "                sync_device()\n",
    "                end2 = time.perf_counter()\n",
    "                all_batch_times_model_only.append(end2 - start2)\n",
    "\n",
    "                # collect predictions from outputs2 (or outputs)\n",
    "                if isinstance(outputs2, tuple):\n",
    "                    outputs2 = outputs2[0]\n",
    "                _, preds = torch.max(outputs2, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "\n",
    "    return {\n",
    "        \"batch_times_including_transfer\": np.array(all_batch_times_including_transfer),\n",
    "        \"batch_times_model_only\": np.array(all_batch_times_model_only),\n",
    "        \"all_preds\": np.array(all_preds),\n",
    "        \"all_labels\": np.array(all_labels)\n",
    "    }\n",
    "\n",
    "# --- run warmup and measure ---\n",
    "print(f\"[INFO] Device: {DEVICE}; batch size: {BATCH_SIZE}; dataset size: {len(test_dataset)}\")\n",
    "do_warmup(model, test_loader, warmup_batches=WARMUP_BATCHES)\n",
    "\n",
    "# Clear CUDA cache to get more consistent results \n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "measurements = measure_runs(model, test_loader, runs=MEASUREMENT_RUNS)\n",
    "\n",
    "# --- compute stats ---\n",
    "def summarize_batch_times(batch_times, batch_size=BATCH_SIZE):\n",
    "    # per-image latencies for each batch\n",
    "    per_batch_sizes = np.full_like(batch_times, batch_size, dtype=float)\n",
    "    per_image = batch_times / per_batch_sizes  # seconds per image\n",
    "    return {\n",
    "        \"count_batches\": int(len(batch_times)),\n",
    "        \"median_ms_per_image\": float(np.median(per_image) * 1000.0),\n",
    "        \"mean_ms_per_image\": float(np.mean(per_image) * 1000.0),\n",
    "        \"std_ms_per_image\": float(np.std(per_image) * 1000.0),\n",
    "        \"p95_ms_per_image\": float(np.percentile(per_image, 95) * 1000.0),\n",
    "        \"throughput_img_per_sec (median)\": 1000.0 / float(np.median(per_image) * 1000.0) if np.median(per_image) > 0 else float(\"inf\"),\n",
    "        \"raw_per_image_ms\": per_image * 1000.0  # keep for later analysis/plotting if needed\n",
    "    }\n",
    "\n",
    "batch_size_actual = BATCH_SIZE\n",
    "inc_summary = summarize_batch_times(measurements[\"batch_times_including_transfer\"], batch_size=batch_size_actual)\n",
    "model_only_summary = summarize_batch_times(measurements[\"batch_times_model_only\"], batch_size=batch_size_actual)\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"\\n===== INFERENCE TIMING SUMMARY =====\")\n",
    "print(\"Mode: INCLUDING host->device transfer\")\n",
    "for k, v in inc_summary.items():\n",
    "    if k != \"raw_per_image_ms\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(\"\\nMode: MODEL-ONLY (inputs already on device)\")\n",
    "for k, v in model_only_summary.items():\n",
    "    if k != \"raw_per_image_ms\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(\"====================================\\n\")\n",
    "\n",
    "# --- Accuracy / Reports ---\n",
    "all_preds = measurements[\"all_preds\"][: len(measurements[\"all_labels\"])]  # safety trim\n",
    "all_labels = measurements[\"all_labels\"]\n",
    "correct = (all_preds == all_labels).sum()\n",
    "accuracy = 100.0 * correct / len(all_labels)\n",
    "print(f\"‚úÖ Test Accuracy: {accuracy:.4f}% (n={len(all_labels)})\")\n",
    "\n",
    "# Confusion matrix and classification report \n",
    "try:\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\nConfusion matrix computed.\")\n",
    "    report = classification_report(all_labels, all_preds, target_names=test_dataset.classes, digits=4)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "except Exception as e:\n",
    "    print(\"Failed to compute classification report:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8088d3-b38b-4796-ba44-d7682c3698bd",
   "metadata": {},
   "source": [
    "# Evaluating DeiT-Ti-Distilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306b5cad-8315-4beb-a18f-7789dac09b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T09:09:28.545949Z",
     "iopub.status.busy": "2025-12-03T09:09:28.545400Z",
     "iopub.status.idle": "2025-12-03T09:14:28.370878Z",
     "shell.execute_reply": "2025-12-03T09:14:28.369958Z",
     "shell.execute_reply.started": "2025-12-03T09:09:28.545924Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/mobileViTV2CDS/mobileViTV2CDS-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Seed set to 42 and logged in 'seed_log.json'.\n",
      "MACs: 919,051,542\n",
      "FLOPs: 1,838,103,084\n",
      "Params: 5,525,958\n",
      "Total Trainable Parameters in deit_tiny_distilled model is: 5,525,958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 ‚Äî Loss: 0.8670, Val Accuracy: 59.83%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 7.472 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 ‚Äî Loss: 0.7299, Val Accuracy: 64.10%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.500 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 ‚Äî Loss: 0.6903, Val Accuracy: 64.10%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.580 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 ‚Äî Loss: 0.6689, Val Accuracy: 67.95%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 ‚Äî Loss: 0.6177, Val Accuracy: 75.64%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.414 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 ‚Äî Loss: 0.6148, Val Accuracy: 74.36%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.337 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 ‚Äî Loss: 0.5746, Val Accuracy: 79.49%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.540 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 ‚Äî Loss: 0.5404, Val Accuracy: 71.79%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.257 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 ‚Äî Loss: 0.5729, Val Accuracy: 67.95%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.292 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 ‚Äî Loss: 0.5470, Val Accuracy: 70.09%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.464 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11 ‚Äî Loss: 0.4872, Val Accuracy: 72.22%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.374 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12 ‚Äî Loss: 0.4858, Val Accuracy: 85.90%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.687 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13 ‚Äî Loss: 0.4449, Val Accuracy: 82.05%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.431 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14 ‚Äî Loss: 0.4293, Val Accuracy: 81.62%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.434 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15 ‚Äî Loss: 0.4469, Val Accuracy: 82.48%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.437 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  16 ‚Äî Loss: 0.4214, Val Accuracy: 79.49%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.495 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  17 ‚Äî Loss: 0.3755, Val Accuracy: 85.04%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 5.413 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  18 ‚Äî Loss: 0.3510, Val Accuracy: 82.05%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 5.531 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19 ‚Äî Loss: 0.3529, Val Accuracy: 81.20%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 5.544 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 ‚Äî Loss: 0.3684, Val Accuracy: 83.33%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 5.423 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21 ‚Äî Loss: 0.3252, Val Accuracy: 87.61%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.628 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  22 ‚Äî Loss: 0.3667, Val Accuracy: 78.63%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.401 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  23 ‚Äî Loss: 0.3272, Val Accuracy: 86.75%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.269 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24 ‚Äî Loss: 0.2479, Val Accuracy: 84.19%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.356 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  25 ‚Äî Loss: 0.3226, Val Accuracy: 84.62%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.382 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  26 ‚Äî Loss: 0.2970, Val Accuracy: 76.50%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 5.381 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  27 ‚Äî Loss: 0.2992, Val Accuracy: 90.17%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.340 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  28 ‚Äî Loss: 0.2732, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.445 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  29 ‚Äî Loss: 0.2461, Val Accuracy: 89.32%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.409 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30 ‚Äî Loss: 0.2354, Val Accuracy: 89.32%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.412 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  31 ‚Äî Loss: 0.2869, Val Accuracy: 91.88%\n",
      "‚úÖ New best model saved.\n",
      "‚è±Ô∏è Epoch Time: 5.390 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  32 ‚Äî Loss: 0.2432, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 1/20\n",
      "‚è±Ô∏è Epoch Time: 5.346 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  33 ‚Äî Loss: 0.2521, Val Accuracy: 88.03%\n",
      "‚è≥ Patience Counter: 2/20\n",
      "‚è±Ô∏è Epoch Time: 5.312 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  34 ‚Äî Loss: 0.2121, Val Accuracy: 88.89%\n",
      "‚è≥ Patience Counter: 3/20\n",
      "‚è±Ô∏è Epoch Time: 5.257 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  35 ‚Äî Loss: 0.2161, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 4/20\n",
      "‚è±Ô∏è Epoch Time: 5.333 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  36 ‚Äî Loss: 0.2371, Val Accuracy: 87.61%\n",
      "‚è≥ Patience Counter: 5/20\n",
      "‚è±Ô∏è Epoch Time: 5.322 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  37 ‚Äî Loss: 0.2383, Val Accuracy: 91.45%\n",
      "‚è≥ Patience Counter: 6/20\n",
      "‚è±Ô∏è Epoch Time: 5.375 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  38 ‚Äî Loss: 0.2081, Val Accuracy: 88.89%\n",
      "‚è≥ Patience Counter: 7/20\n",
      "‚è±Ô∏è Epoch Time: 5.392 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  39 ‚Äî Loss: 0.2242, Val Accuracy: 89.74%\n",
      "‚è≥ Patience Counter: 8/20\n",
      "‚è±Ô∏è Epoch Time: 5.403 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  40 ‚Äî Loss: 0.1999, Val Accuracy: 90.60%\n",
      "‚è≥ Patience Counter: 9/20\n",
      "‚è±Ô∏è Epoch Time: 5.386 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  41 ‚Äî Loss: 0.1650, Val Accuracy: 91.88%\n",
      "‚è≥ Patience Counter: 10/20\n",
      "‚è±Ô∏è Epoch Time: 5.354 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  42 ‚Äî Loss: 0.2151, Val Accuracy: 89.32%\n",
      "‚è≥ Patience Counter: 11/20\n",
      "‚è±Ô∏è Epoch Time: 5.555 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  43 ‚Äî Loss: 0.2076, Val Accuracy: 91.03%\n",
      "‚è≥ Patience Counter: 12/20\n",
      "‚è±Ô∏è Epoch Time: 5.505 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  44 ‚Äî Loss: 0.2015, Val Accuracy: 88.46%\n",
      "‚è≥ Patience Counter: 13/20\n",
      "‚è±Ô∏è Epoch Time: 5.482 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  45 ‚Äî Loss: 0.2075, Val Accuracy: 88.03%\n",
      "‚è≥ Patience Counter: 14/20\n",
      "‚è±Ô∏è Epoch Time: 5.579 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  46 ‚Äî Loss: 0.1791, Val Accuracy: 88.89%\n",
      "‚è≥ Patience Counter: 15/20\n",
      "‚è±Ô∏è Epoch Time: 5.562 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  47 ‚Äî Loss: 0.1660, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 16/20\n",
      "‚è±Ô∏è Epoch Time: 5.472 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  48 ‚Äî Loss: 0.1874, Val Accuracy: 90.17%\n",
      "‚è≥ Patience Counter: 17/20\n",
      "‚è±Ô∏è Epoch Time: 5.546 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  49 ‚Äî Loss: 0.1742, Val Accuracy: 89.74%\n",
      "‚è≥ Patience Counter: 18/20\n",
      "‚è±Ô∏è Epoch Time: 5.645 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 ‚Äî Loss: 0.1720, Val Accuracy: 88.89%\n",
      "‚è≥ Patience Counter: 19/20\n",
      "‚è±Ô∏è Epoch Time: 5.468 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  51 ‚Äî Loss: 0.1589, Val Accuracy: 89.32%\n",
      "‚è≥ Patience Counter: 20/20\n",
      "‚è±Ô∏è Epoch Time: 5.467 seconds\n",
      "üõë Early stopping triggered.\n",
      "\n",
      "üéØ Best Accuracy: 91.88% at Epoch 31\n",
      "\n",
      "===== TRAINING TIME SUMMARY =====\n",
      "‚è±Ô∏è First Epoch Time:       7.472 seconds\n",
      "‚è±Ô∏è Total Training Time:    279.239 seconds\n",
      "‚è±Ô∏è Avg Epoch Time:         5.475 seconds\n",
      "‚è±Ô∏è Time to Best Epoch (31): 170.480 seconds\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from torchvision.transforms import ColorJitter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from itertools import product\n",
    "import time\n",
    "#Flops and efficiency logging\n",
    "import time\n",
    "from ptflops import get_model_complexity_info\n",
    "# Seed setting\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === Reproducibility ===\n",
    "def set_seed(seed: int = 42, save_path: str = \"seed_log.json\"):\n",
    "    \"\"\"\n",
    "    Set the random seed for Python, NumPy, and PyTorch.\n",
    "    Saves the seed to a file so it can be reused later.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Save seed info\n",
    "    seed_data = {\n",
    "        \"seed\": seed\n",
    "    }\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(seed_data, f)\n",
    "\n",
    "    print(f\"[INFO] Seed set to {seed} and logged in '{save_path}'.\")\n",
    "set_seed (42)\n",
    "\n",
    "# === Set device ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"Return number of trainable params.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#Code for noise addition\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0.0, std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img).astype(np.float32) / 255.0\n",
    "        noise = np.random.normal(self.mean, self.std, img.shape)\n",
    "        noisy_img = np.clip(img + noise, 0, 1)\n",
    "        return Image.fromarray((noisy_img * 255).astype(np.uint8))\n",
    "\n",
    "class RandomNoiseBlurOrJitter:\n",
    "    def __init__(self, prob=0.2, noise_std=0.05, blur_radius=1, jitter_params=None):\n",
    "        self.prob = prob\n",
    "        self.noise_transform = AddGaussianNoise(std=noise_std)\n",
    "        self.blur_radius = blur_radius\n",
    "        self.jitter_transform = ColorJitter(**(jitter_params or {\n",
    "            'brightness': 0.2,\n",
    "            'contrast': 0.2,\n",
    "            'saturation': 0.2,\n",
    "            'hue': 0.1\n",
    "        }))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            choice = random.choice(['noise', 'blur', 'jitter'])\n",
    "            if choice == 'noise':\n",
    "                img = self.noise_transform(img)\n",
    "            elif choice == 'blur':\n",
    "                img = img.filter(ImageFilter.GaussianBlur(radius=self.blur_radius))\n",
    "            elif choice == 'jitter':\n",
    "                img = self.jitter_transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "#Data transformation and loading\n",
    "\n",
    "# === Data transforms ===\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(270),\n",
    "    RandomNoiseBlurOrJitter(prob=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    RandomNoiseBlurOrJitter(prob=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "\n",
    "# === Load datasets ===\n",
    "train_dataset = datasets.ImageFolder('CDS_Dataset/train', transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder('CDS_Dataset/val', transform=transform_val)\n",
    "class_names = train_dataset.classes\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Instantiate and move to device\n",
    "model = timm.create_model('deit_tiny_distilled_patch16_224', pretrained=False, num_classes=len(class_names)).to(device)\n",
    "\n",
    "model.to(device)\n",
    "macs, params = get_model_complexity_info(\n",
    "    model,\n",
    "    (3, 224, 224),  # input size\n",
    "    as_strings=False,   # üëà key: return float values\n",
    "    print_per_layer_stat=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Convert MACs ‚Üí FLOPs (1 MAC = 2 FLOPs)\n",
    "flops = macs * 2  \n",
    "\n",
    "print(f\"MACs: {macs:,}\")   # commas for readability\n",
    "print(f\"FLOPs: {flops:,}\") # expanded number\n",
    "print(f\"Params: {params:,}\")\n",
    "print(f\"Total Trainable Parameters in deit_tiny_distilled model is: {count_params(model):,}\")\n",
    "# === Loss and optimizer ===\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "scheduler = None\n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Training with Early Stopping ===\n",
    "best_acc = 0.0\n",
    "epochs = 200\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "best_epoch = 0\n",
    "\n",
    "first_epoch_time = None\n",
    "total_training_time = 0.0\n",
    "# We'll store each epoch's elapsed time so we can accurately sum up to best_epoch later\n",
    "epoch_times = []\n",
    "\n",
    "epochs_completed = 0  # counts how many full epochs we actually ran\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- start epoch timer ----\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_start = time.perf_counter()\n",
    "    # ---------------------------\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1:>3} ‚Äî Loss: {avg_loss:.4f}, Val Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    # --- Decide improvement ---\n",
    "    improved = False\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        improved = True\n",
    "\n",
    "        # save model\n",
    "        torch.save(model.state_dict(), 'CDS_best_scratch_deit_tiny_distilled.pth')\n",
    "        print(\"‚úÖ New best model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚è≥ Patience Counter: {patience_counter}/{patience}\")\n",
    "\n",
    "    # ---- stop epoch timer ----\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_end = time.perf_counter()\n",
    "    epoch_time = epoch_end - epoch_start\n",
    "\n",
    "    # record times\n",
    "    epoch_times.append(epoch_time)\n",
    "    total_training_time += epoch_time\n",
    "    epochs_completed += 1\n",
    "\n",
    "    if first_epoch_time is None:\n",
    "        first_epoch_time = epoch_time\n",
    "\n",
    "    print(f\"‚è±Ô∏è Epoch Time: {epoch_time:.3f} seconds\")\n",
    "\n",
    "    # Early stopping check AFTER timing so final epoch time is included\n",
    "    if patience_counter >= patience:\n",
    "        print(\"üõë Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# End training loop\n",
    "avg_epoch_time = total_training_time / epochs_completed if epochs_completed > 0 else None\n",
    "\n",
    "# --- Compute time_to_best_epoch correctly ---\n",
    "if best_epoch > 0 and len(epoch_times) >= best_epoch:\n",
    "    # best_epoch is 1-based; sum epoch_times up to and including best_epoch\n",
    "    time_to_best_epoch = sum(epoch_times[:best_epoch])\n",
    "else:\n",
    "    time_to_best_epoch = None\n",
    "\n",
    "print(f\"\\nüéØ Best Accuracy: {best_acc*100:.2f}% at Epoch {best_epoch}\")\n",
    "\n",
    "# === Print timing summary ===\n",
    "print(\"\\n===== TRAINING TIME SUMMARY =====\")\n",
    "print(f\"‚è±Ô∏è First Epoch Time:       {first_epoch_time:.3f} seconds\" if first_epoch_time is not None else \"First epoch time: N/A\")\n",
    "print(f\"‚è±Ô∏è Total Training Time:    {total_training_time:.3f} seconds\")\n",
    "print(f\"‚è±Ô∏è Avg Epoch Time:         {avg_epoch_time:.3f} seconds\" if avg_epoch_time is not None else \"Avg epoch time: N/A\")\n",
    "\n",
    "if time_to_best_epoch is not None:\n",
    "    print(f\"‚è±Ô∏è Time to Best Epoch ({best_epoch}): {time_to_best_epoch:.3f} seconds\")\n",
    "else:\n",
    "    print(\"‚è±Ô∏è Time to Best Epoch:      No improvement recorded (best never updated)\")\n",
    "\n",
    "print(\"=================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f4426f-944d-47da-9c41-9297d0026f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T14:25:49.011937Z",
     "iopub.status.busy": "2026-02-24T14:25:49.010918Z",
     "iopub.status.idle": "2026-02-24T14:25:51.064296Z",
     "shell.execute_reply": "2026-02-24T14:25:51.062992Z",
     "shell.execute_reply.started": "2026-02-24T14:25:49.011897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Seed set to 42 -> seed_log.json\n",
      "[INFO] Device: cuda; batch size: 32; dataset size: 234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 138\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# --- run warmup and measure ---\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[INFO] Device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEVICE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; batch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBATCH_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; dataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[43mdo_warmup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWARMUP_BATCHES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Clear CUDA cache to get more consistent results (optional)\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEVICE.type == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mdo_warmup\u001b[39m\u001b[34m(model, loader, warmup_batches)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(warmup_batches):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         images, _ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     83\u001b[39m         it = \u001b[38;5;28miter\u001b[39m(loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/mobileViTV2CDS/mobileViTV2CDS-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/mobileViTV2CDS/mobileViTV2CDS-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/mobileViTV2CDS/mobileViTV2CDS-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/mobileViTV2CDS/mobileViTV2CDS-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:331\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# -------------------------\n",
    "# Config (edit as needed)\n",
    "# -------------------------\n",
    "DATA_DIR = \"CDS_Dataset/test\"\n",
    "MODEL_PATH = \"CDS_best_scratch_deit_tiny_distilled.pth\"\n",
    "MODEL_NAME = \"deit_tiny_distilled_patch16_224\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "WARMUP_BATCHES = 30        # warmup to stabilize kernels\n",
    "MEASUREMENT_RUNS = 5       # number of times to sweep the dataset to collect timings\n",
    "PIN_MEMORY = True\n",
    "NUM_WORKERS = 4            \n",
    "SEED = 42\n",
    "# -------------------------\n",
    "\n",
    "# --- reproducibility ---\n",
    "def set_seed(seed=SEED, save_path=\"seed_log.json\"):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump({\"seed\": seed}, f)\n",
    "    print(f\"[INFO] Seed set to {seed} -> {save_path}\")\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# --- dataset & loader ---\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(DATA_DIR, transform=transform_test)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "# --- model load ---\n",
    "model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=len(test_dataset.classes))\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# --- helper to synchronize safely ---\n",
    "def sync_device():\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "# --- warmup ---\n",
    "def do_warmup(model, loader, warmup_batches=WARMUP_BATCHES):\n",
    "    model.eval()\n",
    "    it = iter(loader)\n",
    "    with torch.no_grad():\n",
    "        for i in range(warmup_batches):\n",
    "            try:\n",
    "                images, _ = next(it)\n",
    "            except StopIteration:\n",
    "                it = iter(loader)\n",
    "                images, _ = next(it)\n",
    "            # move to device and run\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            _ = model(images)\n",
    "            sync_device()\n",
    "    print(f\"[INFO] Completed {warmup_batches} warmup batches.\")\n",
    "\n",
    "# --- measurement: returns lists of per-batch times (seconds) for two modes ---\n",
    "def measure_runs(model, loader, runs=MEASUREMENT_RUNS):\n",
    "    model.eval()\n",
    "    all_batch_times_including_transfer = []\n",
    "    all_batch_times_model_only = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for r in range(runs):\n",
    "            # iterate through dataset once\n",
    "            for images, labels in loader:\n",
    "                batch_size = images.size(0)\n",
    "\n",
    "                # 1) Measure end-to-end (host->device transfer + forward)\n",
    "                start = time.perf_counter()\n",
    "                images_dev = images.to(DEVICE, non_blocking=True)\n",
    "                outputs = model(images_dev)\n",
    "                sync_device()\n",
    "                end = time.perf_counter()\n",
    "                all_batch_times_including_transfer.append(end - start)\n",
    "\n",
    "                # 2) Measure model-only: move inputs first (exclude transfer)\n",
    "                images_dev2 = images.to(DEVICE, non_blocking=True)  # move outside timing\n",
    "                sync_device()\n",
    "                start2 = time.perf_counter()\n",
    "                outputs2 = model(images_dev2)\n",
    "                sync_device()\n",
    "                end2 = time.perf_counter()\n",
    "                all_batch_times_model_only.append(end2 - start2)\n",
    "\n",
    "                # collect predictions from outputs2 (or outputs)\n",
    "                if isinstance(outputs2, tuple):\n",
    "                    outputs2 = outputs2[0]\n",
    "                _, preds = torch.max(outputs2, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "\n",
    "    return {\n",
    "        \"batch_times_including_transfer\": np.array(all_batch_times_including_transfer),\n",
    "        \"batch_times_model_only\": np.array(all_batch_times_model_only),\n",
    "        \"all_preds\": np.array(all_preds),\n",
    "        \"all_labels\": np.array(all_labels)\n",
    "    }\n",
    "\n",
    "# --- run warmup and measure ---\n",
    "print(f\"[INFO] Device: {DEVICE}; batch size: {BATCH_SIZE}; dataset size: {len(test_dataset)}\")\n",
    "do_warmup(model, test_loader, warmup_batches=WARMUP_BATCHES)\n",
    "\n",
    "# Clear CUDA cache to get more consistent results \n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "measurements = measure_runs(model, test_loader, runs=MEASUREMENT_RUNS)\n",
    "\n",
    "# --- compute stats ---\n",
    "def summarize_batch_times(batch_times, batch_size=BATCH_SIZE):\n",
    "    # per-image latencies for each batch\n",
    "    per_batch_sizes = np.full_like(batch_times, batch_size, dtype=float)\n",
    "    per_image = batch_times / per_batch_sizes  # seconds per image\n",
    "    return {\n",
    "        \"count_batches\": int(len(batch_times)),\n",
    "        \"median_ms_per_image\": float(np.median(per_image) * 1000.0),\n",
    "        \"mean_ms_per_image\": float(np.mean(per_image) * 1000.0),\n",
    "        \"std_ms_per_image\": float(np.std(per_image) * 1000.0),\n",
    "        \"p95_ms_per_image\": float(np.percentile(per_image, 95) * 1000.0),\n",
    "        \"throughput_img_per_sec (median)\": 1000.0 / float(np.median(per_image) * 1000.0) if np.median(per_image) > 0 else float(\"inf\"),\n",
    "        \"raw_per_image_ms\": per_image * 1000.0  # keep for later analysis/plotting if needed\n",
    "    }\n",
    "\n",
    "batch_size_actual = BATCH_SIZE\n",
    "inc_summary = summarize_batch_times(measurements[\"batch_times_including_transfer\"], batch_size=batch_size_actual)\n",
    "model_only_summary = summarize_batch_times(measurements[\"batch_times_model_only\"], batch_size=batch_size_actual)\n",
    "\n",
    "# --- Print results ---\n",
    "print(\"\\n===== INFERENCE TIMING SUMMARY =====\")\n",
    "print(\"Mode: INCLUDING host->device transfer\")\n",
    "for k, v in inc_summary.items():\n",
    "    if k != \"raw_per_image_ms\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(\"\\nMode: MODEL-ONLY (inputs already on device)\")\n",
    "for k, v in model_only_summary.items():\n",
    "    if k != \"raw_per_image_ms\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(\"====================================\\n\")\n",
    "\n",
    "# --- Accuracy / Reports ---\n",
    "all_preds = measurements[\"all_preds\"][: len(measurements[\"all_labels\"])]  # safety trim\n",
    "all_labels = measurements[\"all_labels\"]\n",
    "correct = (all_preds == all_labels).sum()\n",
    "accuracy = 100.0 * correct / len(all_labels)\n",
    "print(f\"‚úÖ Test Accuracy: {accuracy:.4f}% (n={len(all_labels)})\")\n",
    "\n",
    "# Confusion matrix and classification report \n",
    "try:\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\nConfusion matrix computed.\")\n",
    "    report = classification_report(all_labels, all_preds, target_names=test_dataset.classes, digits=4)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "except Exception as e:\n",
    "    print(\"Failed to compute classification report:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
